choicetools: a package for conjoint analysis and best-worst surveys
========================================================
author: Chris Chapman (ChromeOS) & Eric Bahna (Android Auto), Google
date: July 10, 2019
autosize: true
font-family: 'Arial'

<style>
.small-code pre code {
  font-size: 1em;
}
</style>


```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  cache=TRUE
)
library(choicetools)
```


Choice-Based Conjoint Analysis
========================================================

A Choice-based conjoint (CBC) survey has respondents make tradeoffs among
products. A product has **attributes** such as brand,
performance, and price, and **levels**, such as
brand names or specific prices.

![CBC question](conjoint-slides-figure/cbc-example-chapmanfeit2019.png)


Hypothetical Product: USB Drive
========================================================
class: small-code

We imagine a USB flash drive with five attributes:

```{r}
cbc.attrs     <- c(Brand=4, Style=4, Price=5, Color=2, Size=4)
cbc.levels    <- c("Alpha", "Bravo", "Charlie", "Delta",    # Brand
                   "Shiny", "Flat",  "Sparkly", "Odd",      # Style
                   "$9",  "$14",  "$19",  "$24",  "$29",    # Price
                   "Blue",  "Red",                          # Color
                   "8GB", "16GB", "32GB", "64GB")           # Size
```

Each attribute has 2-5 levels (brand names, price points, etc.)

Given choices for multiple tradeoffs with randomized attributes, we model the contribution each
feature makes (multinomial/conditional logit model):

$$
p(choice | product) \propto preference(product)
$$

$$
preference(product) \propto \sum{preference(attributes)}
$$


Study Setup
=======================
class: small-code

Each respondent answers multiple choices (tasks). We set up the study to ask
12 choices with 3 products on each. The randomized design matrix
will have N=400 versions of the 12-task survey:

```{r}
set.seed(98103)

cbc.tasks     <- 12   # trials per respondent
cbc.concepts  <- 3    # cards per trial
N             <- 400  # N of respondents
```


Design Matrix
========================
class: small-code

Each level should appear
approximately the same number of times, alone and
in combination with every other attribute. This is done with
**`generalMNLrandomTab()`**:

```{r}
cbc.tab <- generateMNLrandomTab(cbc.attrs, respondents=N,
                                cards=cbc.concepts, trials=cbc.tasks )
knitr::kable(head(cbc.tab, 3))  # first choice trial, 3 products
```

In most cases, you would obtain the design matrix from a survey authoring
platform.


Dummy Coded Design Matrix
==============================
class: small-code

We may convert the "tab style" layout to a dummy coded
matrix of 0 and 1:

```{r, echo=FALSE, results='asis'}
cbc.des <- convertSSItoDesign(cbc.tab)     # dummy coded matrix
knitr::kable(head(cbc.des, 6))
```

The first product concept (first row) is a combination of Brand 2,
Style 3, Price level 2, and so forth.


Survey Output as CSV
==============================
class: small-code

Given a design matrix, **`writeCBCdesignCSV()`** produces a
minimal "survey" in CSV format. This is easy to "field" in a classroom.

To ensure the data in the CSV match the design matrix, **`digest`** (Eddelbuettel et al, 2018)
adds a hash value for the design matrix.

```{r}
writeCBCdesignCSV(head(cbc.tab, 3), cards=3, trials=1,
                  attr.list=cbc.attrs, lab.attrs=names(cbc.attrs),
                  lab.levels = cbc.levels)
```


Creating Simulated Preference Data
========================================================
class: small-code

The simplest model is an aggregate multinomial logit model (MNL).
The coefficients are known as *part worths*. These sum to zero across levels
of each attribute.  **`generateRNDpws()`**  simulates part worths.

**`pickMNLwinningCards()`** uses part worths to find a preferred concept for
each task:
```{r}
cbc.pws <- generateRNDpws(cbc.attrs)    # make up some zero-sum part worths
cbc.win <- pickMNLwinningCards(cbc.des, cbc.pws)  # winning cards
knitr::kable(head(cbind(cbc.win, cbc.des), 3))
```

In the first set -- the first three rows -- the third concept
(Brand 3, Style 1, Price 5, etc.) was preferred and selected in the **`cbc.win`**
vector.


Aggregate Multinomial Logit Model
========================================================

The MNL model estimates preference for a product as
proportional to the sum of the *utility* values for its features. Preference
for A vs. B is the proportion of total utility represented by A:

$$
pref(A | \{A, B\}) = \frac{pref(A)}{pref(A)+pref(B)}
$$

Utility is the exponentiated sum of the features' part worth coefficients,
i.e., a product's logit value:

$$
\frac{pref(A)}{pref(A)+pref(B)} = \frac{e^{\sum{PW_A}}}{e^{\sum{PW_A}}+e^{\sum{PW_B}}}
$$

For conceptual simplicity, we leave out the intercepts and error terms.


Aggregate MNL Estimation
=================================
class: small-code

Now we estimate the part worths based on those "observed" choices:
```{r, fig.show='hold', echo=TRUE, results="hide"}
cbc.mnl <- estimateMNLfromDesign(cbc.des, cbc.win, cards=cbc.concepts)
```

We plot those against the original part worths and see near perfect recovery:
```{r, fig.show='hold'}
plot(cbc.pws, cbc.mnl)
```


Write CSV Structure and Read Choices from It
========================================================
class: small-code

It is more interesting to collect real data! Most
of the time one would do that by fielding a survey online using survey authoring
tools such as **Sawtooth Software** or **Qualtrics**. These platforms
display CBC tasks in a suitable format for respondents.

For this vignette, we write out the CSV file, and then read the data:

```{r}
csv.filename <- "~/Downloads/testCBC.csv"
writeCBCdesignCSV(cbc.tab, filename=csv.filename,   # filename="" for console
                  cards=3, trials=12,
                  attr.list=cbc.attrs, lab.attrs=names(cbc.attrs),
                  lab.levels = cbc.levels, overwrite=TRUE)

# read the CSV
csvfile.in  <- readLines(csv.filename)
```


CSV with Random Choices
==========================
class: small-code

If respondents had filled in choices, we could estimate the MNL model from them.
Because they have not, we make some random choices and rewrite the CSV:
```{r}
# Fill in all of the choices with random choices (1, 2, or 3)
lines.with.choices <- which(grepl("CHOICE for Trial [0-9]+", csvfile.in))
csvfile.in[lines.with.choices] <- paste(csvfile.in[lines.with.choices],
                                        sample(cbc.concepts,
                                               length(lines.with.choices),
                                               replace = TRUE))
writeLines(csvfile.in, con=csv.filename)
```
Now we have a CSV that might have been completed by respondents (if they
were answering randomly). We read those data for the design matrix (`cbc.tab`)
using **`readCBCchoices()`**:
```{r}
# get those choices
cbc.choices <- readCBCchoices(cbc.tab, filename=csv.filename,
                              cards=3, trials=12, verbose=FALSE)

```


Estimation of Random Choice Data
===================================
class: small-code

**`estimateMNLfromDesign()`** estimates part worths from
data. It is primarily for didactic purposes, with an easy-to-understand
gradient implementation. Hierarchical Bayes estimation (*next slide*) is better
for production work.

We plot the part worths and see (for these random data) that estimates are
mostly near zero, with no correspondence to the original part worths:
```{r}
cbc.mnl2 <- estimateMNLfromDesign(cbc.des, cbc.choices, cards=cbc.concepts,
                                  no.output = TRUE)
plot(cbc.pws, cbc.mnl2)
abline(h=0)
```



Hierarchical Bayes Estimation
========================================================

Hierachical Bayes (HB) estimation is typically used for choice models to estimate
a mixed effects model. The *upper level* has fixed effects estimates
for the sample, while the *lower level* gives estimates for each
individual respondent within the distribution.

To estimate the hierarchical Bayes model, use the function
`estimateMNLfromDesignHB()`. This function is a wrapper that
simplifies the data setup and calls `ChoiceModelR::choicemodelr()`
(Sermas, 2012). It uses the *tab* format for the design matrix.

HB uses iterative MCMC estimation. For speed here,
we specify 2000 total MCMC draws (burn-in and posterior); in practice,
this would typically be 10000s, as MCMC needs a long
burn-in period for such data.

`estimateMNLfromDesignHB()` includes several common HB arguments:
- the proportion of the MCMC chain that is regarded as posterior
draws  (`pitersUsed`)
- whether to save the MCMC chain ("draws") for each respondent (`drawKeep`)
- the frequency of posterior draws to retain (every K'th draw in the
chain to avoid autocorrelation; `drawKeepK`)


HB Estimation
========================================================
class: small-code

```{r}
# replace 30% of the perfect "winning" vector with random draws
cbc.win2    <- cbc.win
cbc.replace <- sample(length(cbc.win2), length(cbc.win2)*0.3)  # to replace
cbc.win2[cbc.replace] <- sample(3, length(cbc.replace), replace=TRUE)

# estimate using the design and winning cards
cbc.hb <- estimateMNLfromDesignHB(tmp.des=cbc.tab, tmp.win=cbc.win2,
                                  kCards=cbc.concepts, kTrials=cbc.tasks,
                                  kResp=N , mcmcIters=2000)
```


Get Individual Estimates
========================================================
class: small-code

Estimates may be
extracted from the HB model with **`extractHBbetas()`** (and we add respondent
IDs):

```{r}
cbc.est        <- data.frame(extractHBbetas(cbc.hb, cbc.attrs))
names(cbc.est) <- cbc.levels
cbc.est$ID     <- 1:nrow(cbc.est)   # set respondent ID

# mean of MCMC chain per individual
head(cbc.est)
```


Plot Individual HB Estimates
===============================
class: small-code

It is helpful to plot individuals' estimates, as this is informative about
the variation in preferences for features. **`ggridges`** works well (next slide):
```{r, eval=FALSE}
library(ggplot2)
library(reshape2)
cbc.m <- melt(cbc.est, id.vars = "ID")

library(ggridges)
ggplot(data=cbc.m, aes(x=value, y=variable, group=variable)) +
      geom_density_ridges(scale=0.9, alpha=0, jittered_points=TRUE,
                          rel_min_height=0.005,
                          position="points_sina",
                          point_color = "blue", point_alpha=1/sqrt(N),
                          point_size=2.5) +
        ylab("Attribute / Level") +
        xlab("Relative preference (blue circles=individuals)")
```

Because we are using simulated data, these will be Guassian. In real data,
you might see other patterns such as bimodal distributions.


Individual estimates
==============================
```{r, echo=FALSE, dpi=300, fig.width=12, fig.height=8, fig.show="hold", fig.align="left"}
library(ggplot2)
library(reshape2)
cbc.m <- melt(cbc.est, id.vars = "ID")
library(ggridges)
ggplot(data=cbc.m, aes(x=value, y=variable, group=variable)) +
      geom_density_ridges(scale=0.9, alpha=0, jittered_points=TRUE,
                          rel_min_height=0.005,
                          position="points_sina",
                          point_color = "blue", point_alpha=1/sqrt(N),
                          point_size=2.5) +
        theme(text = element_text(size=20),
        axis.text.x = element_text(angle=90, hjust=1)) +
        ylab("Attribute / Level") +
        xlab("Relative preference (blue circles=individuals)")
```


Preference Share (Market Simulation)
=========================================
class: small-code

Share of preference (aka "market share") may be estimated using
the **`marketSim()`** function. Compare:
- Flat 8GB Blue drive at \$9 from Alpha **vs.**
- Odd 64GB Red drive at \$24 from Bravo

We specify the sets of attributes for each product and compare
them. In this case, we will use first choice preference, where
each individual is regarded as "purchasing" the item with highest preference;
other options in **`marketSim()`** include share of preference at the individual
level, and first choice with randomization:


```{r}
prod1 <- c(6, 16, 14,  9, 1)  # attribute cols: Flat 8GB Blue $9 Alpha
prod2 <- c(8, 19, 15, 12, 2)  # attribute cols: Odd 64GB Red $24 Bravo
usb.pref  <- marketSim(
  cbc.est,                    # matrix of individual-level utilities
  list(prod1, prod2),         # list of products to compare
  use.none=FALSE,             # we have no "none" column
  style="first")              # estimate share by first-choice approach

# see the overall preference share for the two products
colMeans(usb.pref)
```
Between just these two products, we estimate that
`r round(colMeans(usb.pref)[1]*100)`% of respondents prefer product 1,
the $9 flat 8GB drive from Alpha.


Classroom Usage
=========================================
To use this package in a classroom setting:

- Cover the concepts of choice-based conjoint analysis
- Show product attributes and tasks are randomly created
- Write out a CSV file
- Share the CSV and have each student complete a block in the shared document
- Download the spreadsheet CSV, read the answers, and estimate the results
- Share the results and discuss them

In classroom settings, the individual level plots often lead
to interesting discussion and demonstration that the method "works".


Features Beyond CBC
=========================================

The **`choicetools`** package includes support for many other features of CBC
models and related marketing analyses that are beyond the scope of this
vignette. Those include:

- MaxDiff / Best-Worst Scaling, with support to import models from Sawtooth
Software and Qualtrics. Unlike the largely didactic support for CBC models,
the MaxDiff features are intended to be production quality. Cf. Bahna & Chapman (2018).
- Composite Perceptual Maps for brand positioning.
- Experimental CBC models to assess attribute importance. With inspiration
from random forest variable importance methods, this method omits an attribute
and examines the change in predictive validity under oblation to determine the
importance of that attribute.


=========================================

# Thank you! + Q&A + References

**Package in development**: https://github.com/cnchapman/choicetools

Bahna, E., and Chapman, CN (2018). Constructed, Augmented MaxDiff. In
B. Orme, ed., *Proc 2018 Sawtooth Software Conference*.

Chapman, CN, and Feit, EMF (2019). *R for Marketing Research and Analytics*,
2nd ed. Chapter 13: Choice Modeling. New York: Springer.

Eddelbuettel, D; with A Lucas, J Tuszynski,
H Bengtsson, S Urbanek, M Frasca, B Lewis, M Stokely,
H Muehleisen, D Murdoch, J Hester, W Wu, Q Kou,
T Onkelinx, Ml Lang, V Simko, K Hornik and R Neal.
(2018). **digest**: Create Compact Hash Digests of R Objects. R package
version 0.6.18. https://CRAN.R-project.org/package=digest

Rossi, PE, Allenby, GM, and McCulloch, RE (2005).
*Bayesian Statistics and Marketing*. New York: Wiley.

Sermas, Ryan (2012). **ChoiceModelR**: Choice Modeling in R. R package version 1.2.
https://CRAN.R-project.org/package=ChoiceModelR

Wickham, H. (2016). *ggplot2: Elegant Graphics for Data Analysis*. New York: Springer.

Wilke, CO. (2018). **ggridges**: Ridgeline Plots in 'ggplot2'. R package version 0.5.1.
https://CRAN.R-project.org/package=ggridges
